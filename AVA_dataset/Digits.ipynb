{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadData(filename, load2=True, load3=True):\n",
    "  \"\"\"Loads data for 2's and 3's\n",
    "  Inputs:\n",
    "    filename: Name of the file.\n",
    "    load2: If True, load data for 2's.\n",
    "    load3: If True, load data for 3's.\n",
    "  \"\"\"\n",
    "  assert (load2 or load3), \"Atleast one dataset must be loaded.\"\n",
    "  data = np.load(filename)\n",
    "  if load2 and load3:\n",
    "    inputs_train = np.hstack((data['train2'], data['train3']))\n",
    "    inputs_valid = np.hstack((data['valid2'], data['valid3']))\n",
    "    inputs_test = np.hstack((data['test2'], data['test3']))\n",
    "    target_train = np.hstack((np.zeros((1, data['train2'].shape[1])), np.ones((1, data['train3'].shape[1]))))\n",
    "    target_valid = np.hstack((np.zeros((1, data['valid2'].shape[1])), np.ones((1, data['valid3'].shape[1]))))\n",
    "    target_test = np.hstack((np.zeros((1, data['test2'].shape[1])), np.ones((1, data['test3'].shape[1]))))\n",
    "  else:\n",
    "    if load2:\n",
    "      inputs_train = data['train2']\n",
    "      target_train = np.zeros((1, data['train2'].shape[1]))\n",
    "      inputs_valid = data['valid2']\n",
    "      target_valid = np.zeros((1, data['valid2'].shape[1]))\n",
    "      inputs_test = data['test2']\n",
    "      target_test = np.zeros((1, data['test2'].shape[1]))\n",
    "    else:\n",
    "      inputs_train = data['train3']\n",
    "      target_train = np.zeros((1, data['train3'].shape[1]))\n",
    "      inputs_valid = data['valid3']\n",
    "      target_valid = np.zeros((1, data['valid3'].shape[1]))\n",
    "      inputs_test = data['test3']\n",
    "      target_test = np.zeros((1, data['test3'].shape[1]))\n",
    "\n",
    "  return inputs_train, inputs_valid, inputs_test, target_train, target_valid, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs_train, inputs_valid, inputs_test, target_train, target_valid, target_test = LoadData('digits.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_train_ints = target_train.astype(np.int64)\n",
    "newArr = []\n",
    "for i in xrange(target_train_ints.shape[1]):\n",
    "    curr_el = target_train_ints[0][i]\n",
    "    newArr.append(np.array([curr_el, 1 - curr_el], np.int32))\n",
    "    #print target_train_ints[0][i].shape\n",
    "target_input = np.asarray(newArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 256])\n",
    "W1 = tf.Variable(tf.zeros([256, 30]))\n",
    "b1 = tf.Variable(tf.zeros([30]))\n",
    "\n",
    "W2 = tf.Variable(tf.zeros([30, 2]))\n",
    "b2 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "hidden_layer = tf.matmul(x, W1) + b1\n",
    "output = tf.matmul(hidden_layer, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(output)                     # Actual output of our network\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])    # Expected output of our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(50, 650, 50):\n",
    "    sess.run(train_step, feed_dict={x: inputs_train.T[i-50:i], y_: target_input[i-50:i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
